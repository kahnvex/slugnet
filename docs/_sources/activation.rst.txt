Activation Functions
====================

Neural networks rely on a nonlinear transformation to learn
nonlinear relationships in data. These nonlinear transformations
are typically fixed functions that are applied after a linear transformation
of the data. The linear transformation uses learned weights, while the
nonlinear function is fixed in that there are no learned parameters. In
most cases, these nonlinear functions can be thought of as activation
functions that indicate the state of a unit within a layer of a neural
network, given some data.

.. automodule:: slugnet.activation
  :show-inheritance:
  :members:
